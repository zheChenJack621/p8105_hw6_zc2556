---
title: "P8105-hw6-zc2556"
author: "Zhe Chen"
date: "2020/11/30"
output: github_document
---



### Libraries and Basics

```{r, warning=FALSE, include=FALSE}
library(tidyverse)
library(modelr)
library(mgcv)
set.seed(621)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(
  theme_minimal()+
  theme(legend.position = "bottom")
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continous.fill = "viridis"
)

scale_color_discrete = scale_colour_viridis_d()
scale_fill_discrete = scale_fill_viridis_d

```

## Problem 1

```{r}
#read in the dataset
homicide_df = 
  read_csv("./homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

Start with one city

```{r}
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")
#build the model
glm(resolution ~ victim_age + victim_race + victim_sex, 
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```

Across cities

```{r}
models_results_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI")) 

```

plot

```{r}
models_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```


## Problem 2

### Import and clean the data 

```{r, warning= FALSE, message=FALSE}
birthweight = 
  read_csv("./birthweight.csv") %>%
  drop_na() %>%
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace),
    parity = as.factor(parity)
  ) %>%
  #exclude variables with only one level
  select(
    -pnumlbw, -pnumsga
  )
```

While checking the data frame, we noticed there existed some plausible values in the data set:
 
We have one 0 value in column "menarche", representing the motherâ€™s age at menarche is 0. We could consider it as a missing value but since there might be some special cases, we decided to keep it in our data set.

Since we only have one value (0), in column "pnumlbw" and "pnumsga", we decided to exclude these two columns for the conveniance of constructing model.


### Model building

```{r}
#fit the regression model for birthweight
birthw_model = 
  lm(bwt~ fincome + babysex + bhead + blength + gaweeks, data = birthweight)
summary(birthw_model)
```

From the summary, we are quite confident for our model because both R-squared and adjusted R-squared are high (>0.5). Since variable "wtgain" doesn't effect the model building, terms are shown in "NA". 

```{r}
birthw_model_result =
  birthw_model %>% 
    broom::tidy() %>% 
    select(term, estimate, p.value) %>%
    filter(p.value <= 0.05) %>%
    knitr::kable(digits = 3)

#make a tidy result
birthw_model_result
```

We made a tidy result including all statistical significant variables and presented above.

### Plot

```{r}
birthweight %>%
  modelr::add_residuals(birthw_model) %>%
  modelr::add_predictions(birthw_model) %>%
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed", color = "red")
```

In general, from the residuals vs fitted plot, since the majority of points bounces randomly above and below the reference line, we are quite confident that the linear assumption is satisfied. However, we can spot some outliers.   

### Model Comparisions

build two other models

Model with length and mom age:

```{r, message=FALSE}
birthw_model_len_age =  
  lm(bwt~ blength + momage, data = birthweight)
summary(birthw_model_len_age)
```

Model with length, head circumference, gender and interaction:

```{r}
birthw_model_head =
  lm(bwt~ blength + babysex + bhead + blength*babysex*bhead, data = birthweight)
summary(birthw_model_head)
```

Comparison: 

```{r}
#prepare trainning and testing data sets
cv_df =
  crossv_mc(birthweight, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

```{r}
#calculate MSE
cv_df_test = 
  cv_df %>% 
  mutate(
    my_mod  = map(train, ~lm(bwt~ fincome + babysex + bhead + blength + gaweeks, data = .x)),
    len_mod = map(train, ~lm(bwt~ blength + momage, data = .x)),
    head_mod = map(train, ~lm(bwt~ blength + babysex + bhead + blength*babysex*bhead, data = .x))
    ) %>% 
  mutate(
    rmse_my = map2_dbl(my_mod, test, ~rmse(model = .x, data = .y)),
    rmse_len = map2_dbl(len_mod, test, ~rmse(model = .x, data = .y)),
    rmse_head = map2_dbl(head_mod, test, ~rmse(model = .x, data = .y))
    )
```

Plot

```{r}
cv_df_test %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin()+
  labs(
    title = "Comparision of Three Linear Models",
    x = "Model",
    y = "RMSE"
  ) + 
  
  theme(legend.position = "bottom")
```


We made a violin plot to compare the prediction error of three models. My model has a low prediction error compared the other two models. Thus, among these three models, my model (fincome, babysex, bhead, blength, gaweeks) is the best. 


## Problem 3

```{r}
#include dataset 
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

```


5000 for bootstrap

```{r}
#function of bootstrap
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

#bootstrap for 5000
boot_straps = 
  data_frame(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )

boot_straps
```

Bootstrap and model building

```{r}
#find rsquared
bootstrap_results = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap_sample, -models) %>%
  unnest(results) %>%
  select(
    strap_number, r.squared
  )
```

```{r}
#find coefficient
bootstrap_results_coef = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap_sample, -models) %>%
  unnest(results) %>%
  select(
    strap_number, term, estimate
  ) %>%
  pivot_wider(
    names_from = term,
    values_from = estimate
  )
```

```{r}
#merge two dataset
bootstrap_results_all = 
  merge(bootstrap_results, bootstrap_results_coef, by = "strap_number")
bootstrap_results_all = 
  bootstrap_results_all %>%
  mutate(
    log_beta0_beta1 = log(bootstrap_results_all[,3]*tmin)
  ) %>%
  select(
    strap_number, r.squared, log_beta0_beta1
  )

head(bootstrap_results_all)
```

### Plot

```{r}
bootstrap_results_all %>%
  ggplot(aes(x =  r.squared)) +
  geom_density() +
  labs(
    title = "Plot of R Squared Estimates for Bootstrap with Size of 5000",
    x = "Estimate of R Squared",
    y = "Density"
  ) + 
  theme(legend.position = "bottom")
```

```{r}
bootstrap_results_all %>%
  ggplot(aes(x = log_beta0_beta1)) +
  geom_density() +
  labs(
    title = "Plot of log coefficient Estimates for Bootstrap with Size of 5000",
    x = "Estimate of Log(beta0*beta1)",
    y = "Density"
  ) + 
  theme(legend.position = "bottom")
```
We can observe a normal distribution for the both plots.

### find the CI

```{r}
#tidy the data 
bootstrap_results_all %>%
  pivot_longer(
    r.squared:log_beta0_beta1,
    names_to = "term",
    values_to = "estimate"
  ) %>%
  group_by(term) %>% 
  summarize(
    ci_lower = quantile(estimate, 0.025), 
    ci_upper = quantile(estimate, 0.975))
```






