---
title: "P8105-hw6-zc2556"
author: "Zhe Chen"
date: "2020/11/30"
output: github_document
---



### Libraries and Basics

```{r, warning=FALSE, include=FALSE}
library(tidyverse)
library(modelr)
library(mgcv)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(
  theme_minimal()+
  theme(legend.position = "bottom")
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continous.fill = "viridis"
)

scale_color_discrete = scale_colour_viridis_d()
scale_fill_discrete = scale_fill_viridis_d

```

## Problem 1

```{r}
#read in the dataset
homicide_df = 
  read_csv("./homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

Start with one city

```{r}
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")
#build the model
glm(resolution ~ victim_age + victim_race + victim_sex, 
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```

Across cities

```{r}
models_results_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI")) 

```

plot

```{r}
models_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```


## Problem 2

### Import and clean the data 

```{r, warning= FALSE, message=FALSE}
birthweight = 
  read_csv("./birthweight.csv") %>%
  drop_na() %>%
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace),
    parity = as.factor(parity)
  ) %>%
  #exclude variables with only one level
  select(
    -pnumlbw, -pnumsga
  )
```

While checking the data frame, we noticed there existed some plausible values in the data set:
 
 * We have one 0 value in column "menarche", representing the motherâ€™s age at menarche is 0. We could consider it as a missing value but since there might be some special cases, we decided to keep it in our data set.
 * Since we only have one value (0), in column "pnumlbw" and "pnumsga", we decided to exclude these two columns for the conveniance of constructing model.


### Model building

```{r}
#fit the regression model for birthweight
birthw_model = 
  lm(bwt~ fincome + babysex + bhead + blength + gaweeks, data = birthweight)
summary(birthw_model)
```

From the summary, we are quite confident for our model because both R-squared and adjusted R-squared are high (>0.5). Since variable "wtgain" doesn't effect the model building, terms are shown in "NA". 

```{r}
birthw_model_result =
  birthw_model %>% 
    broom::tidy() %>% 
    select(term, estimate, p.value) %>%
    filter(p.value <= 0.05) %>%
    knitr::kable(digits = 3)

#make a tidy result
birthw_model_result
```

We made a tidy result including all statistical significant variables and presented above.

### Plot

```{r}
birthweight %>%
  modelr::add_residuals(birthw_model) %>%
  modelr::add_predictions(birthw_model) %>%
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed", color = "red")
```

In general, from the residuals vs fitted plot, since the majority of points bounces randomly above and below the reference line, we are quite confident that the linear assumption is satisfied. However, we can spot some outliers.   

### Model Comparisions

build two other models

Model with length and mom age:

```{r, message=FALSE}
birthw_model_len_age =  
  lm(bwt~ blength + momage, data = birthweight)
summary(birthw_model_len_age)
```

Model with length, head circumference, gender and interaction:

```{r}
birthw_model_head =
  lm(bwt~ blength + babysex + bhead + blength*babysex*bhead, data = birthweight)
summary(birthw_model_head)
```

Comparison: 

```{r}
#prepare trainning and testing data sets
cv_df =
  crossv_mc(birthweight, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

```{r}
#calculate MSE
cv_df_test = 
  cv_df %>% 
  mutate(
    my_mod  = map(train, ~lm(bwt~ fincome + babysex + bhead + blength + gaweeks, data = .x)),
    len_mod = map(train, ~lm(bwt~ blength + momage, data = .x)),
    head_mod = map(train, ~lm(bwt~ blength + babysex + bhead + blength*babysex*bhead, data = .x))
    ) %>% 
  mutate(
    rmse_my = map2_dbl(my_mod, test, ~rmse(model = .x, data = .y)),
    rmse_len = map2_dbl(len_mod, test, ~rmse(model = .x, data = .y)),
    rmse_head = map2_dbl(head_mod, test, ~rmse(model = .x, data = .y))
    )
```

Plot

```{r}
cv_df_test %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

We made a violin plot to compare the prediction error of three models. My model has a low prediction error compared the other two models. Thus, among these three models, my model (fincome + babysex + bhead + blength + gaweeks) is the best. 


## Problem 3

```{r}
#set up 
set.seed(621)
n_ent = 30
sigm_ent = 5

#function to find the estimated mean and p-value
sim_mean_p = function(n, mu, sigm) {
  x = rnorm(n, mean = mu, sd = sigm)
  t = broom::tidy(t.test(x))
  fun_res = tibble(
    mu_hat = t$estimate,
    p_value = t$p.value
    )
  return(fun_res)
}

```


5000 for mu = 0

```{r}
#function to stimulate for 5000 times 
stimulate = function(mu) {
  output_mu= vector("list", 5000)
  for(i in 1:5000) {
    output_mu[[i]] = sim_mean_p(n_ent, mu, sigm_ent)
  }
  sim_result = bind_rows(output_mu)
  return(sim_result)
}

#when mu = 0
mu0 = stimulate(0)
mu0
```

Proportion of Rejecting the Null based on 0.05 alpha when mu = 0.

```{r}
#function to find the proportion of rejecting the null
test = function(stimulate_data, true_mu) {
  sim_reject = 
    stimulate_data %>%
      filter(p_value < 0.05) %>%
      summarise(
        prop_reject = n()/5000
      )
  mu =
    tibble(
      true_mu = true_mu
    )
  sim_reject = bind_cols(sim_reject, mu)
  return(sim_reject)
}

#for mu = 0 
test(mu0,0)
```

### Plot the Proportion of Reject VS True Mean

Apply functions 
```{r}
#make a data frame including mu = 1-6
for (i in 1:6) {
  assign(paste0("mu", i), stimulate(i))
}
```

Make a table for plotting
```{r}
#make a data frames including the proportion and true means
mu_all = list(mu0,mu1,mu2,mu3,mu4,mu5,mu6)
for (i in 1:7) {
  assign(paste0("prop_table", i), test(as.data.frame(mu_all[i]),i))
}
prop_table = bind_rows(prop_table1, prop_table2, prop_table3, prop_table4, prop_table5, prop_table6, prop_table7) %>%
  mutate(
    true_mu = true_mu - 1
  )
prop_table
```

Plot

```{r}
prop_table %>%
  ggplot(aes(x = as.factor(true_mu), y = prop_reject, group  = 1)) +
  geom_point() +
  geom_line() +
  ylim (0,1) +
  geom_text(aes(label = prop_reject, hjust = 0, vjust = 0.5, angle = -25))+
  labs(
    title = "5000 Times of Stimulation for 6 Means",
    x = "True Mean",
    y = "Proportion of Rejection Times"
  ) + 
  
  theme(legend.position = "bottom")
```

From the plot, we can observe a increasing trend while the true mean increases from 0 to 6 and the proportion of rejection times approaches to 1. From the plot, we can conclude that the much more different of the alternative hypothesis (larger mean in this case), the more powerful of the test (greater proportion of rejection times). While the mean of the tested mean is the same as the null, the proportion of rejection times is pretty close to the level of significance (0.05 in our case). 

### Plot the Average Estimate of mu VS True Mean

```{r}
#find the average estimate of mu
find_av = function(stimulate_data, true_mu) {
  av_est = 
    stimulate_data %>%
      summarise(
        mu_bar = round(mean(mu_hat),digits = 4)
      )
  mu =
    tibble(
      true_mu = true_mu
    )
  av_est = bind_cols(av_est, mu)
  return(av_est)
}

#create table of the average of estimates
for (i in 1:7) {
  assign(paste0("av_est", i), find_av(as.data.frame(mu_all[i]),i))
}
av_est = bind_rows(av_est1, av_est2, av_est3, av_est4, av_est5, av_est6, av_est7) %>%
  mutate(
    true_mu = true_mu - 1
  )
av_est  
```

Plot

```{r}
av_est %>%
  ggplot(aes(x = as.factor(true_mu), y = mu_bar, group  = 1)) +
  geom_point() +
  geom_line() +
  geom_text(aes(label = mu_bar, hjust = 0, vjust = 1.1))+
  labs(
    title = "5000 Times of Stimulation for 6 Means",
    x = "True Mean",
    y = "Average of Estimated Mean"
  ) + 
  
  theme(legend.position = "bottom")
```

From the plot, we can clearly observe a nearly perfect linear relation between the average of estimated means and the true mean, showing that the average of estimated means is equal to the true mean. Thus, we are confident to estimate the true mean with the sample mean when the number of simulation times is large enough. 

### Plot the Average Estimate (rejected) of mu VS True Mean

```{r}
#find the average estimate of mu (rejected)
find_av_rej = function(stimulate_data, true_mu) {
  av_est_rej = 
    stimulate_data %>%
      filter(p_value < 0.05) %>%
      summarise(
        mu_bar_rej = round(mean(mu_hat),digits = 4)
      )
  mu =
    tibble(
      true_mu = true_mu
    )
  av_est_rej = bind_cols(av_est_rej, mu)
  return(av_est_rej)
}

#create table of the average of estimates (rejected)
for (i in 1:7) {
  assign(paste0("av_est_rej", i), find_av_rej(as.data.frame(mu_all[i]),i))
}
av_est_rej = bind_rows(av_est_rej1, av_est_rej2, av_est_rej3, av_est_rej4, av_est_rej5, av_est_rej6, av_est_rej7) %>%
  mutate(
    true_mu = true_mu - 1
  )
av_est_rej  
```

Plot

```{r}
av_est_rej %>%
  ggplot(aes(x = as.factor(true_mu), y = mu_bar_rej, group  = 1)) +
  geom_point() +
  geom_line() +
  geom_text(aes(label = mu_bar_rej, hjust = 0, vjust = 1.1))+
  labs(
    title = "5000 Times of Stimulation for 6 Means (Rejected)",
    x = "True Mean",
    y = "Average of Estimated Mean (Rejected)"
  ) + 
  theme(legend.position = "bottom")
```

From the plot, we don't observe a nearly perfect linear relation between the rejected average of estimated means and the true mean. When the true mean is 0, 3, 4, 5, 6, the average of estimated rejected means is  close to the true mean. When is 1 or 2, the average of estimated rejected means is not close to the true mean. This is consistent with the plot of the true mean vs proportion of rejections times, showing that the more powerful the test, the more accurate of the estimation from the rejected means. 




